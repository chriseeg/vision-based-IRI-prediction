{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Kopie von rdd_IRI_pytorch.ipynb","provenance":[{"file_id":"1Ez72SYuJfseInOtgYuZBMLa9VhPUJfS8","timestamp":1621851971352}],"collapsed_sections":[],"mount_file_id":"1Ez72SYuJfseInOtgYuZBMLa9VhPUJfS8","authorship_tag":"ABX9TyNUGh3ctw9Bfp3GyJ8NbXlI"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Mn0jk4os2oPA"},"source":["# IRI Classification\n","\n","based on https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce"]},{"cell_type":"markdown","metadata":{"id":"QBQ3ZjSr3T7u"},"source":["Imports"]},{"cell_type":"code","metadata":{"id":"1bxHhPCT2oPC"},"source":["!pip install efficientnet_pytorch\n","\n","from IPython.core.interactiveshell import InteractiveShell\n","import seaborn as sns\n","# PyTorch\n","from torchvision import transforms, datasets, models\n","import torch\n","from torch import optim, cuda\n","from torch.utils.data import DataLoader, sampler\n","import torch.nn as nn\n","from efficientnet_pytorch import EfficientNet\n","\n","\n","import warnings\n","warnings.filterwarnings('ignore', category=FutureWarning)\n","\n","# Data science tools\n","import numpy as np\n","import pandas as pd\n","import os\n","import csv\n","from shutil import copy,rmtree,copytree\n","from tqdm import tqdm\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n","from pprint import pprint\n","import random\n","#random = random.Random(17)\n","\n","# Image manipulations\n","from PIL import Image\n","\n","# Useful for examining network\n","from torchsummary import summary\n","\n","# Timing utility\n","from timeit import default_timer as timer\n","\n","# Visualizations\n","import matplotlib.pyplot as plt\n","#%matplotlib inline\n","plt.rcParams['font.size'] = 14\n","\n","# Printing out all outputs\n","InteractiveShell.ast_node_interactivity = 'all'\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UwEOG33H3V6y"},"source":["Weights & Biases initialization"]},{"cell_type":"code","metadata":{"id":"L7kOf5TINen1"},"source":["# Weights and Biases is used to track and analyse results in their web-service. To disable it, comment out all lines containing \"wandb\"\n","!pip install --upgrade wandb --quiet\n","!wandb login (wandb credentials)\n","import wandb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RI8wIaTf2oPI"},"source":["### PARAMETERS"]},{"cell_type":"code","metadata":{"id":"zvZlr_05l_JY"},"source":["#@title Chose ride/image combination\n","run_title = \"Large Class\" #@param {type:\"string\"}\n","\n","ride_location = \"sinsheim\" #@param [\"sinsheim\", \"karlsruhe\", \"ka_si\"]\n","test_location = \"same\" #@param [\"same\", \"sinsheim\", \"karlsruhe\", \"ka_si\"]\n","image_construction = \"C\" #@param [\"A\",\"B_full\",\"B_crop\",\"B_top\",\"C\"]\n","test_image_construction = \"C\" #@param [\"A\",\"B_full\",\"B_crop\",\"B_top\",\"C\"]\n","MODEL_NAME = \"efficientnet-b0\" #@param [\"vgg16\", \"resnet50\", \"efficientnet-b*\", \"resnet50_object_detection\"] {allow-input: true}\n","number_of_repetitions =  1#@param {type:\"integer\"}\n","\n","IRI_BINNING = True #@param {type:\"boolean\"}\n","OVERSAMPLING = \"balanced_1.0\" #@param [\"True\", \"False\", \"\\\"balanced_1.0\\\"\"] {type:\"raw\", allow-input: true}\n","save_saliency = False #@param {type:\"boolean\"}\n","\n","special_csv = \"False\" #@param [\"False\",\"fine\",\"binary\",\"mehrspurig außerorts\",\"mehrspurig außerorts ohne erneuerte Fahrbahn\", \"extra features\"]\n","drive_path = \"/content/drive/My Drive/Masterthesis\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5UwI2Zkv2oPJ","executionInfo":{"status":"ok","timestamp":1619880580928,"user_tz":-120,"elapsed":17017,"user":{"displayName":"Christian Seeger","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBdZSahLB91Z8XWEq8kZMwE7a1EhKVD2OWNPFGH6k=s64","userId":"02533968630071158910"}},"outputId":"08876d9a-17a5-4c2c-935c-63a8b8c4479e"},"source":["# Training, validation, test-splits\n","splits = {\n","  \"train_part\" : 0.6,\n","  \"val_part\" : 0.2,\n","  \"test_part\" : 0.2\n","}\n","wandb_project = \"rdd-iri-analysis\" #\"rdd-IRI-pytorch\"\n","\n","# Location of data\n","zip_path = '{}/Data/01 IRI prediction/99 zipped/{}_{}.zip'.format(drive_path,ride_location,image_construction).replace(' ', '\\ ')\n","\n","\n","if image_construction != \"A\":  \n","  image_construction_csv = \"BC\"\n","else:\n","  image_construction_csv = \"A\"\n","csv_path = \"{}/Data/01 IRI prediction/99 zipped/{}_{}_IRI.csv\".format(drive_path,ride_location,image_construction_csv)\n","\n","if special_csv == \"mehrspurig außerorts\":\n","  csv_path = drive_path + \"/Data/01 IRI prediction/99 zipped/sinsheim_BC_IRI mehrspurig außerorts.csv\"\n","  print(special_csv)\n","elif special_csv == \"mehrspurig außerorts ohne erneuerte Fahrbahn\":\n","  csv_path = drive_path + \"/Data/01 IRI prediction/99 zipped/sinsheim_BC_IRI mehrspurig außerorts ohne erneuerte Fahrbahn.csv\"\n","  print(special_csv)\n","elif special_csv == \"fine\":\n","  csv_path = drive_path + \"/Data/01 IRI prediction/99 zipped/sinsheim_BC_IRI fine.csv\"\n","  print(special_csv)\n","elif special_csv == \"binary\":\n","  csv_path = drive_path + \"/Data/01 IRI prediction/99 zipped/sinsheim_BC_IRI binary.csv\"\n","  print(special_csv)\n","elif special_csv == \"extra features\":\n","  csv_path = drive_path + \"/Data/01 IRI prediction/99 zipped/sinsheim_BC_damages.csv\"\n","  print(special_csv)\n","\n","\n","datadir = '/content/data/'\n","result_dir = drive_path + \"/Results/Image analysis\"\n","test_inferences_dir = drive_path + \"/Results/Test inferences\"\n","trained_resnet50_path = drive_path + \"/Code/02 Object detection/trained_resnet50_backbone\"\n","\n","dirs = {\n","  \"train\": datadir + 'train/',\n","  \"val\": datadir + 'valid/',\n","  \"test\": datadir + 'test/'\n","}\n","\n","# Model\n","BATCH_SIZE = 64 # Default: 128, best result: 64\n","FROZEN = True   # Freeze training of pretrained model weights\n","INPUT_SIZE = (600,600) \n","DATA_BLOCKS = True # take sample blocks of 10 images for allocation to train-, validation- and test data\n","OVERSAMPLING_VAL_TEST = False # Oversampling of validation- and test-data\n","\n","# Avoiding overfitting\n","N_EPOCHS = 120\n","MAX_EPOCHS_STOP = 30\n","\n","save_file_name = MODEL_NAME + '_state-dict.pt'\n","checkpoint_path = MODEL_NAME + '_checkpoint.pt'\n","\n","# Whether to train on a gpu\n","train_on_gpu = cuda.is_available()\n","print(f'Train on gpu: {train_on_gpu}')\n","\n","multi_gpu = False\n","# Number of gpus\n","if train_on_gpu:\n","  gpu_count = cuda.device_count()\n","  print(f'{gpu_count} gpus detected.')\n","  if gpu_count > 1:\n","    multi_gpu = True\n","  else:\n","    multi_gpu = False"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on gpu: True\n","1 gpus detected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7BKPuJ1j8DrR"},"source":["# Create training, validation & test dataset folders"]},{"cell_type":"code","metadata":{"id":"sufR2unaN2KN"},"source":["!mkdir -p $datadir\n","# copy images from zip folder in drive\n","!unzip -q $zip_path -d $datadir\n","os.chdir(datadir)\n","!find . -name '.DS_Store' -type f -delete\n","os.chdir(\"/content\")\n","\n","# Check if training and test dataset are the same\n","if test_location is not \"same\":\n","  print(\"Loading additional Test-Data for \" + test_location)\n","  # Test dataset locations\n","  if test_image_construction is not \"A\":  \n","    test_image_construction_csv = \"BC\"\n","  else:\n","    test_image_construction_csv = \"A\"\n","  test_zip_path = '{}/Data/01 IRI prediction/99 zipped/{}_{}.zip'.format(drive_path,ride_location,test_image_construction).replace(' ', '\\ ')\n","  test_csv_path = drive_path + \"/Data/01 IRI prediction/{}_{}_IRI.csv\".format(test_location,test_image_construction_csv)\n","\n","  test_datadir = \"/content/test_data/\"\n","  test_dirs = {\n","    \"train\": test_datadir + 'train/',\n","    \"val\": test_datadir + 'valid/',\n","    \"test\": test_datadir + 'test/'\n","  }\n","  !mkdir -p $test_datadir\n","  # copy images from zip folder in drive\n","  !unzip -q $test_zip_path -d $test_datadir\n","  os.chdir(test_datadir)\n","  !find . -name '.DS_Store' -type f -delete\n","  os.chdir(\"/content\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sN3WdEyiPXOH"},"source":["def read_csv(path):\n","  with open(path, mode='r') as infile:\n","    reader = csv.reader(infile)\n","    data_list = [rows for rows in reader]\n","  return data_list\n","\n","def iri_binning(iri_list):\n","  # group IRI labels into three classes:\n","  # 1_3\n","  # 4\n","  # 5_6_7_8\n","  binned_iris = []\n","  for img,iri in iri_list:\n","    if iri in ['1','2','3'] :\n","      x = \"iri_1_3\"\n","    if iri in ['5','6','7','8']:\n","      x = \"iri_5_8\"\n","    if iri == '4':\n","      x = \"iri_4\"\n","    binned_iris.append([img,x])\n","  return binned_iris\n","\n","def iri_binning_2(iri_list):\n","  # Group IRI labels into three classes, without upper limit for class iri_5__\n","  # 1_2_3\n","  # 4\n","  # 5_6_7_...\n","  binned_iris = []\n","  for img,iri in iri_list:\n","    iri = str(iri)\n","    if iri in ['1','2','3']:\n","      x = \"iri_1_3\"\n","    elif iri == '4':\n","      x = \"iri_4\"\n","    else:\n","      x = \"iri_5__\"  \n","    binned_iris.append([img,x])\n","  return binned_iris\n","\n","# Randomly split and arrange data \n","def split_up_data(classes,data,split_ranges):\n","  # Shuffle data and separate by classes\n","  data_by_class = []\n","  for c in classes:\n","    class_data = [d for d in data if d[1] == c]\n","    random.Random(17).shuffle(class_data)\n","    data_by_class.append(class_data)\n","\n","  # Split data in training, validation and testing\n","  split_data = []\n","  \n","  for split in split_ranges:\n","    # iterate train,val,test\n","    split_d = []\n","    for d in data_by_class:\n","      # iterate classes\n","      range_from = round(split[0]*len(d))\n","      range_to = round(split[1]*len(d))\n","      split_d.append(d[range_from:range_to])\n","    split_data.append(split_d)\n","  return split_data\n","\n","def split_up_data_blocks(classes,data,split_ranges,block_size = 10):\n","  # Create blocks of unshuffeled images\n","  data_blocks = []\n","  for i in range(0, len(data), block_size):\n","    data_blocks.append(data[i:i+block_size])\n","\n","  # Randomly split data from blocks into training, validation and testing\n","  split_data = []\n","  len_data_blocks = len(data_blocks)\n","  random.Random(17).shuffle(data_blocks)\n","  # iterate train,val,test\n","  for split in split_ranges:\n","    split_d = []\n","    range_from = round(split[0]*len_data_blocks)\n","    range_to = round(split[1]*len_data_blocks)\n","    new_blocks = data_blocks[range_from:range_to]\n","    new_data = [d for b in new_blocks for d in b]\n","    split_d.extend(new_data)\n","    # Separate by classes\n","    data_by_class = []\n","    for c in classes:\n","      class_data = [d for d in split_d if d[1] == c]\n","      data_by_class.append(class_data)\n","    split_data.append(data_by_class)\n","  return split_data\n","\n","### create class image folders for each iri value\n","def create_image_folders(csv_path, zip_path, IRI_BINNING, datadir, dirs_dict, splits, DATA_BLOCKS = True, OVERSAMPLING = False, OVERSAMPLING_VAL_TEST = False):\n","  print(csv_path)\n","  iri_csv = read_csv(csv_path)\n","  data = [[d[0],str(round(float(d[1])))] for d in iri_csv]\n","  print(\"Total images: {}\".format(len(data)))\n","\n","  if IRI_BINNING == 2:\n","    data = iri_binning_2(data)\n","  elif IRI_BINNING:\n","    data = iri_binning(data)\n","  \n","  \n","  splits_names = [\"training\", \"validation\", \"test\"]\n","  classes = set([d[1] for d in data])\n","\n","  n_classes = len(classes)\n","  print(\"Classes: \" + str(classes))\n","  \n","  # Make classnames with two digits\n","  if n_classes >= 10 and not IRI_BINNING:\n","    classes = [(\"0\" + c)[-2:]  for c in classes]\n","    data = [[d[0],(\"0\" + d[1])[-2:]] for d in data]\n","  \n","  classes = list(sorted(classes))\n","  \n","  # Define ranges of training, validation and test data\n","  split_ranges = [[0,splits[\"train_part\"]],\n","            [splits[\"train_part\"],splits[\"train_part\"] + splits[\"val_part\"]],\n","            [splits[\"train_part\"] + splits[\"val_part\"],1]]\n","\n","  if DATA_BLOCKS:\n","    split_data = split_up_data_blocks(classes,data,split_ranges)\n","  else:\n","    split_data = split_up_data(classes,data,split_ranges)\n","\n","  \n","  if OVERSAMPLING_VAL_TEST:\n","    oversampling_splits = [0,1,2]\n","  else:\n","    oversampling_splits = [0]\n","  \n","  for split_i in oversampling_splits:\n","    split_d = split_data[split_i] \n","\n","    if type(OVERSAMPLING) is not bool and OVERSAMPLING.startswith(\"balanced\"):\n","      # Upsampling underrepresented & downsampling overrepresented classes\n","      sampling_parameter = float(OVERSAMPLING.split(\"_\")[1])\n","      \n","      train_counts = [len(d) for d in split_d]\n","      average_class_size = sum(train_counts)/len(train_counts)\n","      for i,count in enumerate(train_counts):\n","        cl = classes[i]\n","        if count < average_class_size:\n","          # Replicate random training-images for underrepresented classes\n","          upsample = min(count,round(abs(average_class_size - count)*sampling_parameter))\n","          print(\"Oversampling \"+str(upsample)+\" \"+ splits_names[split_i]+\" images in class \"+cl)\n","          random_sample = random.Random(42).sample([d for d in split_d[i] if d[1] == cl], upsample)\n","          split_d[i].extend(random_sample)\n","        else:\n","          # Remove random training-images from overrepresented classes\n","          downsample = round(abs(average_class_size - count)*sampling_parameter)\n","          print(\"Downsampling \"+str(downsample)+\" \"+ splits_names[split_i]+\" images in class \"+cl)\n","          #print(downsample)\n","          for _ in range(downsample):\n","            split_d[i].remove(random.choice(split_d[i]))\n","          \n","    elif OVERSAMPLING:\n","      # Oversampling training images\n","      train_counts = [len(d) for d in split_d]\n","      max_train_count = max(train_counts)\n","      # Replicate random training-images for underrepresented classes\n","      for i,count in enumerate(train_counts):\n","        cl = classes[i]\n","        if count < max_train_count:\n","          upsample = max_train_count - count\n","          print(\"Oversampling \"+str(upsample)+\" \"+ splits_names[split_i]+\" images in class \"+cl)\n","          random_sample = random.Random(42).sample([d for d in split_d[i] if d[1] == cl], upsample)\n","          split_d[i].extend(random_sample)\n","\n","  # Create folders for train,val,test for each class\n","\n","  size_dict = {}\n","  dirs = [d for _,d in dirs_dict.items()]\n","  old_datadir = os.path.join(datadir,zip_path.split(\"/\")[-1].split(\".\")[0])\n","\n","  for i,dir in enumerate(dirs):\n","    # iterate train,val,test paths\n","    sizes = {}\n","    try:\n","      rmtree(dir)\n","      os.mkdir(dir)\n","    except:\n","      os.mkdir(dir)\n","\n","    for j,class_name in enumerate(tqdm(classes)):\n","      # iterate classes\n","      new_class_dir = os.path.join(dir, class_name)\n","      try:\n","        os.mkdir(new_class_dir)\n","      except:\n","        pass\n","      for img in split_data[i][j]:\n","        img_name = img[0]\n","        old_img_path = os.path.join(old_datadir,img_name)\n","        new_img_path = os.path.join(new_class_dir,img_name)\n","        if img_name in os.listdir(new_class_dir):\n","          new_img_path = new_img_path.split(\".jpg\")[0] + \"_2.jpg\"\n","        _ = copy(old_img_path,new_img_path)\n","\n","      sizes[class_name] = len(os.listdir(new_class_dir))\n","    size_dict[dir] = sizes\n","\n","  print(size_dict)\n","\n","  return n_classes,size_dict\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w__YMNPk2oP8"},"source":["# Dataset creation\n","\n","## Data Augmentation\n","\n","Because there are a limited number of images in some categories, we can use image augmentation to artificially increase the number of images \"seen\" by the network. This means for training, we randomly resize and crop the images and also flip them horizontally. A different random transformation is applied each epoch (while training), so the network effectively sees many different versions of the same image. All of the data is also converted to Torch `Tensor`s before normalization. The validation and testing data is not augmented but is only resized and normalized. The normalization values are standardized for Imagenet. \n","\n","## Data Iterators\n","\n","To avoid loading all of the data into memory at once, we use training `DataLoaders`. First, we create a dataset object from the image folders, and then we pass these to a `DataLoader`. At training time, the `DataLoader` will load the images from disk, apply the transformations, and yield a batch. To train and validation, we'll iterate through all the batches in the respective `DataLoader`. \n","\n","One crucial aspect is to `shuffle` the data before passing it to the network. This means that the ordering of the image categories changes on each pass through the data (one pass through the data is one training epoch).\n","\n","### Batches\n","\n","The shape of a batch is `(batch_size, color_channels, height, width)`. \n","\n","We can iterate through the `DataLoaders` when doing training, validation, and testing. This construction avoids the need to load all the data into memory and also will automatically apply the transformations to each batch. On each epoch, the `Random` transformations will be different so the network will essentially see multiple versions of each training image. "]},{"cell_type":"code","metadata":{"id":"0vm5cD9JXBF1"},"source":["from torchvision.datasets import ImageFolder\n","class MyImageFolder(ImageFolder):\n","    \"\"\"A generic data loader where the images are arranged in this way: ::\n","\n","        root/dog/xxx.png\n","        root/dog/xxy.png\n","        root/dog/xxz.png\n","\n","        root/cat/123.png\n","        root/cat/nsdf3.png\n","        root/cat/asd932_.png\n","\n","    Args:\n","        root (string): Root directory path.\n","        transform (callable, optional): A function/transform that  takes in an PIL image\n","            and returns a transformed version. E.g, ``transforms.RandomCrop``\n","        target_transform (callable, optional): A function/transform that takes in the\n","            target and transforms it.\n","        loader (callable, optional): A function to load an image given its path.\n","        is_valid_file (callable, optional): A function that takes path of an Image file\n","            and check if the file is a valid file (used to check of corrupt files)\n","\n","     Attributes:\n","        classes (list): List of the class names sorted alphabetically.\n","        class_to_idx (dict): Dict with items (class_name, class_index).\n","        imgs (list): List of (image path, class_index) tuples\n","    \"\"\"\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Args:\n","            index (int): Index\n","\n","        Returns:\n","            tuple: (sample, target, samplename) where target is class_index of the target class.\n","        \"\"\"\n","        path, target = self.samples[index]\n","        sample = self.loader(path)\n","        sample_name = path.split(\"/\")[-1]\n","\n","        if self.transform is not None:\n","            sample = self.transform(sample)\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","            sample_name = self.target_transform(sample_name)\n","\n","        return sample, target, sample_name"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X-cIlCs_2oP8"},"source":["def create_datasets(dirs, INPUT_SIZE, BATCH_SIZE):\n","  # Image transformations\n","  image_transforms = {\n","    # Train uses data augmentation\n","    'train':\n","    transforms.Compose([\n","      transforms.Resize(size=INPUT_SIZE),\n","      #transforms.RandomResizedCrop(size=INPUT_SIZE, scale=(0.8, 1.0), ratio = (1.0,1.3)),\n","      #transforms.RandomRotation(degrees=15),\n","      transforms.ColorJitter(),\n","      transforms.RandomHorizontalFlip(),\n","      #transforms.CenterCrop(size=TRANSFORM_SIZE),  # Image net standards\n","      transforms.ToTensor(),\n","      transforms.Normalize([0.485, 0.456, 0.406],\n","                          [0.229, 0.224, 0.225])  # Imagenet standards\n","    ]),\n","    # Validation does not use augmentation\n","    'val':\n","    transforms.Compose([\n","      transforms.Resize(size=INPUT_SIZE),\n","      #transforms.CenterCrop(size=TRANSFORM_SIZE),\n","      transforms.ToTensor(),\n","      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    # Test does not use augmentation\n","    'test':\n","    transforms.Compose([\n","      transforms.Resize(size=INPUT_SIZE),\n","      #transforms.CenterCrop(size=TRANSFORM_SIZE),\n","      transforms.ToTensor(),\n","      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","  }\n","\n","  # Datasets from each folder\n","  data = {\n","    'train':\n","    MyImageFolder(root=dirs[\"train\"], transform=image_transforms['train']),\n","    'val':\n","    MyImageFolder(root=dirs[\"val\"], transform=image_transforms['val']),\n","    'test':\n","    MyImageFolder(root=dirs[\"test\"], transform=image_transforms['test'])\n","  }\n","\n","  # Dataloader iterators\n","  dataloaders = {\n","    'train': DataLoader(data['train'], batch_size=BATCH_SIZE, shuffle=True),\n","    'val': DataLoader(data['val'], batch_size=BATCH_SIZE, shuffle=True),\n","    'test': DataLoader(data['test'], batch_size=BATCH_SIZE, shuffle=False)\n","  }\n","\n","  trainiter = iter(dataloaders['train'])\n","  features, labels,_ = next(trainiter)\n","  print(features.shape)\n","  print(labels.shape)\n","\n","  print(\"Dataloaders created\")\n","  return data, dataloaders\n","\n","def imshow_tensor(image, ax=None, title=None):\n","  \"\"\"Imshow for Tensor.\"\"\"\n","\n","  if ax is None:\n","      fig, ax = plt.subplots()\n","\n","  # Set the color channel as the third dimension\n","  image = image.numpy().transpose((1, 2, 0))\n","\n","  # Reverse the preprocessing steps\n","  mean = np.array([0.485, 0.456, 0.406])\n","  std = np.array([0.229, 0.224, 0.225])\n","  image = std * image + mean\n","\n","  # Clip the image pixel values\n","  image = np.clip(image, 0, 1)\n","\n","  ax.imshow(image)\n","  plt.axis('off')\n","\n","  return ax, image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4gUjZToY2oQX"},"source":["# Load Pre-Trained Model for Image Classification\n","\n","- freeze the early layers of the pretrained model\n","- replace the classification module\n","\n","## Approach\n","\n","The approach for using a pre-trained image recognition model:\n","\n","1. Load in pre-trained weights from a network trained on a large dataset\n","2. Freeze all the weights in the lower (convolutional) layers\n","    * Layers to freeze can be adjusted depending on similarity of task to large training dataset\n","3. Replace the classifier (fully connected) part of the network with a custom classifier\n","    * Number of outputs must be set equal to the number of classes\n","4. Train only the custom classifier (fully connected) layers for the task"]},{"cell_type":"code","metadata":{"id":"m-bV6GHT2oQs"},"source":["class CustomModelEfficientNet(nn.Module):\n","  # Class of EfficientNet B0 model with input of image and numeric data\n","  def __init__(self, n_classes, n_extra_features, dropout, frozen):\n","    # Load EfficientNet\n","    super(CustomModelEfficientNet, self).__init__()\n","    self.cnn = EfficientNet.from_pretrained(\"efficientnet-b0\")\n","\n","    # Set parameters to traineable\n","    for param in self.cnn.parameters():\n","        param.requires_grad = not frozen\n","\n","    # Add on classifier in fully connected layer\n","    n_inputs = self.cnn._fc.in_features\n","    self.cnn._fc = nn.Linear(n_inputs, 256)\n","    \n","    # Add numeric extra-features\n","    self.fc1 = nn.Linear(256 + n_extra_features, 60)\n","    self.fc2 = nn.Linear(60, n_classes)\n","\n","    self.dropout = dropout\n","\n","  def forward(self, image, extra_features):\n","    x1 = self.cnn(image)\n","    x2 = extra_features\n","    # combine features from feature-extractor and numeric damage features\n","    x = torch.cat((x1, x2), dim=1)\n","    x = self.fc1(x)\n","    x = F.relu(x)\n","    x = F.dropout(x,p=self.dropout)\n","    x = self.fc2(x)\n","    x = F.softmax(x,dim=1)\n","    return x\n","\n","def get_pretrained_model(model_name, multi_gpu, dropout, frozen = True):\n","  \"\"\"Retrieve a pre-trained model from torchvision\n","\n","  Params\n","  -------\n","      model_name (str): name of the model\n","\n","  Return\n","  --------\n","      model (PyTorch model): cnn\n","\n","  Available pretrained models in pytorch:\n","  --------\n","      resnet18 = models.resnet18(pretrained=True)\n","      alexnet = models.alexnet(pretrained=True)\n","      squeezenet = models.squeezenet1_0(pretrained=True)\n","      vgg16 = models.vgg16(pretrained=True)\n","      densenet = models.densenet161(pretrained=True)\n","      inception = models.inception_v3(pretrained=True)\n","      googlenet = models.googlenet(pretrained=True)\n","      shufflenet = models.shufflenet_v2_x1_0(pretrained=True)\n","      mobilenet = models.mobilenet_v2(pretrained=True)\n","      resnext50_32x4d = models.resnext50_32x4d(pretrained=True)\n","      wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)\n","      mnasnet = models.mnasnet1_0(pretrained=True)\n","  \"\"\"\n","\n","  if model_name == 'vgg16':\n","    model = models.vgg16(pretrained=True)\n","    # Freeze early layers\n","    for param in model.parameters():\n","      param.requires_grad = not frozen\n","    # Add on classifier:\n","    #   Fully connected with ReLU activation (n_inputs, 256)\n","    #   Dropout with adjustable chance of dropping\n","    #   Fully connected with log softmax output (256, n_classes)\n","    classificator_size = 256\n","    n_inputs = model.classifier[6].in_features\n","    model.classifier[6] = nn.Sequential(\n","      nn.Linear(n_inputs, classificator_size), nn.ReLU(), nn.Dropout(dropout),\n","      nn.Linear(classificator_size, n_classes), nn.LogSoftmax(dim=1))\n","    \n","    # Printing classifier\n","    print(\"Classifier:\")\n","    if multi_gpu:\n","      print(model.module.classifier)\n","    else:\n","      print(model.classifier)\n","\n","  elif model_name == 'resnet50':\n","    model = models.resnet50(pretrained=True)\n","    for param in model.parameters():\n","      param.requires_grad = not frozen\n","    # Add on classifier in fully connected layer\n","    n_inputs = model.fc.in_features\n","    model.fc = nn.Sequential(\n","      nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(dropout),\n","      nn.Linear(256, n_classes), nn.LogSoftmax(dim=1))\n","  \n","\n","  elif model_name == 'resnet50_object_detection':\n","    model = models.resnet50(pretrained=True)\n","    print(model)\n","    new_state_dict = torch.load(trained_resnet50_path)\n","    model.load_state_dict(new_state_dict)\n","    for param in model.parameters():\n","      param.requires_grad = not frozen\n","    # Add on classifier in fully connected layer\n","    n_inputs = model.fc.in_features\n","    model.fc = nn.Sequential(\n","      nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(dropout),\n","      nn.Linear(256, n_classes), nn.LogSoftmax(dim=1))\n","    \n","  elif model_name == 'mobilenet_v2':\n","    model = models.mobilenet_v2(pretrained=True)\n","\n","    # Freeze early layers\n","    for param in model.parameters():\n","      param.requires_grad = not frozen\n","    # Add on classifier:\n","    n_inputs = model.classifier[1].in_features\n","    model.classifier = nn.Sequential(\n","      nn.Linear(n_inputs, 1280), nn.ReLU(), nn.Dropout(0.2),\n","      nn.Linear(1280, n_classes), nn.LogSoftmax(dim=1))\n","    # Printing classifier\n","    print(\"Classifier:\")\n","    if multi_gpu:\n","      print(model.module.classifier)\n","    else:\n","      print(model.classifier)\n","\n","  elif model_name.startswith('efficientnet-b'):\n","    if special_csv == \"extra features\":\n","      model = CustomModelEfficientNet(n_classes, n_extra_features, dropout, frozen)\n","    else:\n","      model = EfficientNet.from_pretrained(model_name)\n","      for param in model.parameters():\n","        param.requires_grad = not frozen\n","      # Add on classifier:\n","      n_inputs = model._fc.in_features\n","      model._fc = nn.Sequential(\n","        nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(dropout),\n","        nn.Linear(256, n_classes), nn.LogSoftmax(dim=1))\n","\n","  # Move to gpu and parallelize\n","  if train_on_gpu:\n","    model = model.to('cuda')\n","  if multi_gpu:\n","    model = nn.DataParallel(model)\n","\n","  # Mapping classes to indexes\n","  model.class_to_idx = data['train'].class_to_idx\n","  model.idx_to_class = {\n","    idx: class_\n","    for class_, idx in model.class_to_idx.items()\n","  }\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2tgXotfV2oRF"},"source":["# Saving Model\n","\n","In the `train` function the `state_dict()`, the weights of the best model are saved. To save more information about the model, we use the below function. "]},{"cell_type":"code","metadata":{"id":"ElN77HPL2oRG"},"source":["def save_checkpoint(model, path):\n","    \"\"\"Save a PyTorch model checkpoint\n","\n","    Params\n","    --------\n","        model (PyTorch model): model to save\n","        path (str): location to save model. Must start with `model_name-` and end in '.pth'\n","\n","    Returns\n","    --------\n","        None, save the `model` to `path`\n","\n","    \"\"\"\n","\n","    model_name = path.split('-')[0]\n","    assert (model_name in ['vgg16', 'resnet50'\n","                           ]), \"Path must have the correct model name\"\n","\n","    # Basic details\n","    checkpoint = {\n","        'class_to_idx': model.class_to_idx,\n","        'idx_to_class': model.idx_to_class,\n","        'epochs': model.epochs,\n","    }\n","\n","    # Extract the final classifier and the state dictionary\n","    if model_name == 'vgg16':\n","        # Check to see if model was parallelized\n","        if multi_gpu:\n","            checkpoint['classifier'] = model.module.classifier\n","            checkpoint['state_dict'] = model.module.state_dict()\n","        else:\n","            checkpoint['classifier'] = model.classifier\n","            checkpoint['state_dict'] = model.state_dict()\n","\n","    elif model_name == 'resnet50':\n","        if multi_gpu:\n","            checkpoint['fc'] = model.module.fc\n","            checkpoint['state_dict'] = model.module.state_dict()\n","        else:\n","            checkpoint['fc'] = model.fc\n","            checkpoint['state_dict'] = model.state_dict()\n","\n","    # Add the optimizer\n","    checkpoint['optimizer'] = model.optimizer\n","    checkpoint['optimizer_state_dict'] = model.optimizer.state_dict()\n","        \n","    # Save the data to the path\n","    torch.save(checkpoint, path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qq17gcJ8fC_y"},"source":["# Visualize saliency maps"]},{"cell_type":"markdown","metadata":{"id":"kIsfuKeGfC_6"},"source":["Based on:\n","https://medium.com/datadriveninvestor/visualizing-neural-networks-using-saliency-maps-in-pytorch-289d8e244ab4 "]},{"cell_type":"code","metadata":{"id":"nzdlWziHfC_7"},"source":["# Lists of used images\n","saliency_test_images = {\n","  \"iri_1_3\":[\n","              \"20190819_14-39-18-092_sgm00139.jpg\",\n","\"20190819_13-39-58-707_sgm00080.jpg\",\n","\"20190819_14-39-18-092_sgm00057.jpg\",\n","\"20190819_12-50-08-839_sgm00403.jpg\",\n","\"20190819_12-50-08-839_sgm00402.jpg\",\n","\"20190819_10-32-50-611_sgm01176.jpg\",\n","\"20190816_11-08-09-342_sgm00098.jpg\",\n","\"20190816_10-30-47-864_sgm00029.jpg\"\n","              ],\n","  \"iri_4\":[\n","            \"20190814_14-44-24-433_sgm00060.jpg\",\n","\"20190819_10-32-50-611_sgm00878.jpg\",\n","\"20190819_12-00-05-082_sgm01279.jpg\",\n","\"20190819_10-32-50-611_sgm01008.jpg\",\n","\"20190819_10-32-50-611_sgm01020.jpg\",\n","\"20190819_13-57-11-762_sgm00191.jpg\",\n","\"20190819_14-39-18-092_sgm00202.jpg\",\n","\"20190819_14-39-18-092_sgm00052.jpg\",\n","\"20190819_13-39-58-707_sgm00088.jpg\",\n","\"20190819_11-15-57-991_sgm00095.jpg\",\n","\"20190819_11-15-57-991_sgm00184.jpg\",\n","\"20190816_11-08-09-342_sgm00009.jpg\"\n","            ],\n","  \"iri_5_8\":[\n","              \"20190814_14-44-24-433_sgm00063.jpg\",\n","\"20190819_12-50-08-839_sgm00589.jpg\",\n","\"20190814_14-44-24-433_sgm01330.jpg\",\n","\"20190819_10-32-50-611_sgm01154.jpg\",\n","\"20190819_13-39-58-707_sgm00101.jpg\",\n","\"20190819_11-15-57-991_sgm00123.jpg\",\n","\"20190819_11-15-57-991_sgm00180.jpg\",\n","\"20190819_13-39-58-707_sgm00016.jpg\"]\n","              }\n","\n","\n","def save_saliency_maps(model,dirs,result_dir,transforms,saliency_test_images,run_name,epoch,f1_score):\n","  target_dir = os.path.join(result_dir,run_name,\"saliency_map\")\n","  try:\n","    os.makedirs(target_dir)\n","  except:\n","    pass\n","\n","  # Preprocess image from test dataset\n","  trans = transforms.Compose([\n","    transforms.Resize(size=INPUT_SIZE),\n","    #transforms.CenterCrop(size=TRANSFORM_SIZE),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","  ])\n","  \n","  # Run the model in evaluation mode\n","  _ = model.eval()\n","\n","  for i,iri_class in enumerate(saliency_test_images):\n","    for image_name in saliency_test_images[iri_class]:\n","      # Open image\n","      image_path = os.path.join(dirs['test'],iri_class,image_name)    \n","      f1_round = round(f1_score,3)\n","      f1 = str(f1_round).replace(\".\",\",\")\n","      image_save_name = image_name.split(\".jpg\")[0] + \"_original.jpg\"\n","      \n","      image = Image.open(image_path)\n","      image.save(os.path.join(target_dir,image_save_name))\n","\n","      image = trans(image).unsqueeze_(0).cuda()\n","      # Find the gradient with respect to the input image, so we need to call requires_grad_ on it\n","      _ = image.requires_grad_()\n","\n","      # Forward pass through the model to get the prediction scores.\n","      prediction_scores = model(image)\n","\n","      # Get the index corresponding to the maximum prediction score and the maximum prediction score itself.\n","      prediction_score_max_index = prediction_scores.argmax()\n","      prediction_score_max = prediction_scores[0,prediction_score_max_index]\n","\n","      if prediction_score_max_index == i: \n","        correct = 1\n","      else:\n","        correct = 0\n","\n","      # Backward function on prediction_score_max performs the backward pass in the computation graph and calculates the gradient of \n","      # prediction_score_max with respect to nodes in the computation graph\n","      prediction_score_max.backward()\n","\n","      # Saliency is the gradient with respect to the input image now. But note that the input image has 3 channels,\n","      # R, G and B. To derive a single class saliency value for each pixel (i, j),  we take the maximum magnitude\n","      # across all colour channels.\n","      magnitudes = image.grad.data.abs()\n","      saliency, _ = torch.max(magnitudes,dim=1)\n","      # code to plot the saliency map as a heatmap\n","      fig = plt.figure()\n","      _ = plt.imshow(saliency[0].cpu(), cmap=plt.cm.hot)\n","      #plt.imshow(image.detach().cpu().squeeze(0)[0])\n","      _ = plt.axis('off')\n","      saliency_map_name = image_name.split(\".jpg\")[0] + \"_epoch{}_act{}_pred{}_corr{}_acc{}.png\".format(epoch,i,prediction_score_max_index,correct,f1)\n","      plt.savefig(os.path.join(target_dir,saliency_map_name),bbox_inches='tight')\n","      plt.close(fig)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r9aEJeLR2oQ8"},"source":["# Training & Validation\n","\n","### Training Loop:\n","- iterate through train `DataLoader`\n","- pass one batch through model\n","- After each batch: \n","  - calculate the loss with `criterion(output, targets)`\n","  - calculate the gradients of the loss with respect to the model parameters with `loss.backward()`\n","  - call `optimizer.step()` to update the model parameters with the gradients\n","  - calculate dynamic learnrate with momentum via the optimizer *Adam*\n","- One complete pass through the training data: `epoch`\n","- after training loop:\n","\n","### Validation loop:\n","- iterate through  validation `DataLoader`\n","- calculate classification quality parameter\n","- if quality increases: save model weights, to load a *best model* in the end\n","- if quality doesn't increase for a number of epochs: early stopping"]},{"cell_type":"code","metadata":{"id":"qXeTqESH2oQ8"},"source":["def weights_to_wandb(dictionary, filename):\n","  # Function to store sample weights to Weights and Biases\n","  df = pd.DataFrame.from_dict(dictionary, orient='index')\n","  df.reset_index(level=0, inplace=True)\n","  df.to_csv(filename, index=False, header=[\"Name\",\"Weight\"])\n","  wandb.save(filename)\n","\n","def soft_accuracy(targets, outputs, margin = 1):\n","  # Calculate accuracy, but allow misclassifications within a certain margin\n","  correct = 0\n","  for target, output in zip(targets,outputs):\n","    if target - margin <= output <= target + margin:\n","      correct +=1\n","  acc = correct / len(targets)\n","  return acc\n","\n","\n","def train(model,\n","          learning_rate,\n","          train_loader,\n","          valid_loader,\n","          save_file_name,\n","          max_epochs_stop,\n","          loss_function='NLLLoss',\n","          weight_increase=None,\n","          n_epochs=50):\n","  \"\"\"Train a PyTorch Model\n","\n","  Params\n","  --------\n","      model (PyTorch model): cnn to train\n","      learning_rate (double): learning rate value of optimizer\n","      train_loader (PyTorch dataloader): training dataloader to iterate through\n","      valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n","      save_file_name (str ending in '.pt'): file path to save the model state dict\n","      max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n","      loss_function (nn Loss function)\n","      weight_increase (double): value >=0, that is added to the weight of missclassified samples\n","      n_epochs (int): maximum number of training epochs\n","\n","  Returns\n","  --------\n","      model (PyTorch model): trained cnn with best weights\n","      history (DataFrame): history of train and validation loss and accuracy\n","  \"\"\"\n","  # Define loss function\n","  if loss_function == \"CrossEntropy\":\n","    criterion = nn.CrossEntropyLoss(reduction='none')\n","  else:\n","    criterion = nn.NLLLoss(reduction='none')\n","\n","  # Define Optimizer\n","  optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n","  \n","  print(\"\\nWeights being updated during training:\")\n","  for p in optimizer.param_groups[0]['params']:\n","    if p.requires_grad:\n","      print(p.shape)\n","\n","  # Early stopping intialization\n","  epochs_no_improve = 0\n","  valid_best_macro_fscore = 0\n","  \n","  valid_loss_min = np.Inf\n","  valid_best_acc = 0\n","  history = []\n","\n","  labels = list(model.class_to_idx.keys())\n","\n","  # Number of epochs already trained (if using loaded in model weights)\n","  try:\n","    print(f'Model has been trained for: {model.epochs} epochs.\\n')\n","  except:\n","    model.epochs = 0\n","    print(f'Starting Training from Scratch.\\n')\n","\n","\n","  overall_start = timer()\n","\n","  # Initialize sample weights\n","  sample_weights = {s[0].split(\"/\")[-1]:1 for s in dataloaders[\"train\"].dataset.samples}\n","\n","  # Main loop\n","  for epoch in range(n_epochs):\n","\n","    # keep track of training and validation loss each epoch\n","    train_loss = 0.0\n","    valid_loss = 0.0\n","\n","    train_acc = 0\n","    valid_acc = 0\n","\n","    # Set to training\n","    model.train()\n","    start = timer()\n","\n","    # Training loop\n","    for ii, (data, target, sample_names) in enumerate(train_loader):\n","      # Tensors to gpu\n","      if train_on_gpu:\n","        data, target = data.cuda(), target.cuda()\n","\n","      # Clear gradients\n","      optimizer.zero_grad()\n","      # Predicted outputs are log probabilities\n","      output = model(data)\n","\n","      # Loss calculation\n","      loss = criterion(output, target)\n","      \n","      # Increase weight of missclassified samples\n","      if weight_increase:\n","        _, predicted = torch.max(output.data, 1)\n","        check_list = zip(predicted,target,sample_names)\n","        sample_weights_batch = []\n","        for pred,targ,s_name in check_list:\n","          # Check if samples in batch were misclassified\n","          if pred != targ:\n","            sample_weights[s_name] += weight_increase\n","          # Create list of sample weights in current batch\n","          sample_weights_batch.append(sample_weights[s_name])\n","        # Turn weight vector into tensor\n","        sample_weights_batch = torch.FloatTensor(sample_weights_batch).to('cuda')\n","        # Apply weights onto loss\n","        loss = (loss * sample_weights_batch / sample_weights_batch.sum()).sum()\n","        # Backpropagation of gradients\n","        loss.backward()\n","      else:\n","        # Continue without sample weights\n","        loss = loss.mean()\n","        # Backpropagation of gradients\n","        loss.backward()\n","\n","      # Update the parameters\n","      optimizer.step()\n","\n","      # Track train loss by multiplying average loss by number of examples in batch\n","      train_loss += loss.item() * data.size(0)\n","\n","      # Calculate accuracy by finding max log probability\n","      _, pred = torch.max(output, dim=1)\n","      correct_tensor = pred.eq(target.data.view_as(pred))\n","      # Need to convert correct tensor from int to float to average\n","      accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n","      # Multiply average accuracy times the number of examples in batch\n","      train_acc += accuracy.item() * data.size(0)\n","    \n","      # Track training progress\n","      print(\n","          f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n","          end='\\r')      \n","\n","    # After training loop ends, start validation\n","    else:\n","      model.epochs += 1\n","      \n","      outputs = []\n","      output_probs = []\n","      targets = []\n","\n","      # Don't need to keep track of gradients\n","      with torch.no_grad():\n","        # Set to evaluation mode\n","        model.eval()\n","\n","        # Validation loop\n","        for data, target, sample_names in valid_loader:\n","          # Tensors to gpu\n","          if train_on_gpu:\n","            data, target = data.cuda(), target.cuda()\n","\n","          # Forward pass\n","          output = model(data)\n","          \n","          # Track targets and predictions\n","          out = np.argmax(np.array(output.tolist()),axis=1)\n","          outputs.extend(out)\n","          output_probs.extend(output.tolist())\n","          targets.extend(target.tolist())\n","\n","          # Validation loss\n","          loss = criterion(output, target)\n","          # Multiply average loss times the number of examples in batch\n","          valid_loss += loss.mean().item() * data.size(0)\n","\n","          # Calculate validation accuracy\n","          _, pred = torch.max(output, dim=1)\n","          correct_tensor = pred.eq(target.data.view_as(pred))\n","          accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n","          \n","          # Multiply average accuracy times the number of examples\n","          valid_acc += accuracy.item() * data.size(0)                    \n","\n","\n","      # Calculate average losses\n","      train_loss = train_loss / len(train_loader.dataset)\n","      valid_loss = valid_loss / len(valid_loader.dataset)\n","\n","      # Calculate average accuracy\n","      train_acc = train_acc / len(train_loader.dataset)\n","      valid_acc = valid_acc / len(valid_loader.dataset)\n","\n","      history.append([train_loss, valid_loss, train_acc, valid_acc])\n","\n","      # Calculate soft accuracy\n","      soft_valid_acc = soft_accuracy(targets, outputs)\n","\n","      # Calculate validation quality parameters\n","      macro_precision, macro_recall, macro_fscore,_ = precision_recall_fscore_support(targets, outputs, average='macro')\n","      micro_precision, micro_recall, micro_fscore,_ = precision_recall_fscore_support(targets, outputs, average='micro')\n","      \n","      # Log to weights & biases\n","      wandb.sklearn.plot_confusion_matrix(targets, outputs, labels)\n","      wandb.log({'pr': wandb.plots.precision_recall(targets, output_probs, labels)})\n","      wandb.log({'Training loss': train_loss,\n","                  \"Training accuracy\": train_acc,\n","                  \"Validation loss\": valid_loss,\n","                  \"Validation accuracy\": valid_acc,\n","                  \"Validation soft accuracy\": soft_valid_acc,\n","                  \"Precision macro\": macro_precision,\n","                  \"Precision micro\": micro_precision,\n","                  \"Recall macro\": macro_recall,\n","                  \"Recall micro\": micro_recall,\n","                  \"F-Score macro\": macro_fscore,\n","                  \"F-Score micro\": micro_fscore,\n","                  'Epoch': epoch})                \n","\n","      # Calculate saliency maps\n","      if save_saliency:\n","          save_saliency_maps(model,dirs,result_dir,transforms,saliency_test_images,wandb.run.name,epoch,macro_fscore)\n","\n","      # Print training and validation results\n","      if (epoch + 1) % 100 == 0:\n","        print(\n","            f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n","        )\n","        print(\n","            f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n","        )\n","\n","      # Track best validation accuracy     \n","      if valid_acc > valid_best_acc:\n","        valid_best_acc = valid_acc\n","        wandb.run.summary[\"best_accuracy\"] = valid_best_acc\n","\n","      # Save the model if  macro F-Score increases\n","      if macro_fscore > valid_best_macro_fscore:\n","        valid_best_macro_fscore = macro_fscore\n","        wandb.run.summary[\"Best F-Score macro\"] = macro_fscore\n","        # Save model (weights)\n","        torch.save(model.state_dict(), save_file_name)\n","        wandb.save(save_file_name)\n","        print(\"state_dict saved 👌🏻\")\n","        # Track improvement\n","        epochs_no_improve = 0          \n","        best_epoch = epoch\n","        wandb.run.summary[\"best_epoch\"] = best_epoch\n","\n","      # Otherwise increment count of epochs with no improvement\n","      else:\n","        epochs_no_improve += 1\n","        # Trigger early stopping\n","        if epochs_no_improve >= max_epochs_stop:\n","          print(\n","              f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_best_acc:.2f}%'\n","          )\n","          total_time = timer() - overall_start\n","          print(\n","              f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n","          )\n","\n","          # Load the best state dict\n","          model.load_state_dict(torch.load(save_file_name))\n","          # Attach the optimizer\n","          model.optimizer = optimizer\n","\n","          # Format history\n","          history = pd.DataFrame(\n","              history,\n","              columns=[\n","                  'train_loss', 'valid_loss', 'train_acc',\n","                  'valid_acc'\n","              ])\n","          \n","          # Save sample weights to wandb\n","          weights_to_wandb(sample_weights,\"sample_weights.csv\")\n","\n","          return model, history, sample_weights\n","\n","  # Attach the optimizer\n","  model.optimizer = optimizer\n","  # Record overall time and print out stats\n","  total_time = timer() - overall_start\n","  print(\n","      f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n","  )\n","  print(\n","      f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n","  )\n","\n","  # Save checkpoint (overall model info)\n","  try:\n","    save_checkpoint(model,checkpoint_path)\n","    wandb.save(checkpoint_path)\n","  except:\n","    pass\n","  wandb.save(save_file_name)\n","\n","  # Save sample weights to wandb\n","  weights_to_wandb(sample_weights,\"sample_weights.csv\")\n","\n","  # Format history\n","  history = pd.DataFrame(\n","      history,\n","      columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n","  return model, history, sample_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"23VSmkY7V6sp"},"source":["Testing"]},{"cell_type":"code","metadata":{"id":"UIPNZ0GWV6CW"},"source":["def test_inference(model,dataloaders):\n","  # extract specific run-name from weights & biases\n","  run_name = wandb.run.name.split(\"-\")\n","  run_name = run_name[2] + \"-\" + run_name[0] + \"-\" + run_name[1]\n","  # create filepaths to store .csv results\n","  target_path_1 = os.path.join(test_inferences_dir, run_name + '.csv')\n","  target_path_2 = os.path.join(test_inferences_dir, run_name + '_confidences.csv')\n","\n","  # Load best model\n","  model.load_state_dict(torch.load(save_file_name))\n","\n","  # Initialize list of results\n","  test_inference_results = []\n","  header_1 = [\"Filename\",\"Target\",\"Prediction\",\"Confidence\",\"Confidence Vector\"]\n","\n","  # Set model to inference-only (no training)\n","  with torch.no_grad():\n","    model.eval()\n","    # Iterate testdata\n","    for i, (images, labels, sample_names) in tqdm(enumerate(dataloaders[\"test\"], 0)):\n","      # Get inference results\n","      outputs = model(images.to('cuda'))\n","      _, predicted = torch.max(outputs.data, 1)\n","      # Get classification probabilities\n","      probabilities = outputs.data.tolist()\n","      batch_size = len(predicted)\n","      for j,pred_item in enumerate(predicted.tolist()):\n","        # Collect target info\n","        sample_name, sample_target = dataloaders[\"test\"].dataset.samples[i*batch_size + j]\n","        sample_name = sample_name.split(\"/\")[-1]\n","        # Calculate confidence\n","        confidence = np.exp(max(probabilities[j]))\n","        # Consolidate result info\n","        line = [sample_name,sample_target,pred_item,confidence]\n","        test_inference_results.append(line)\n","\n","  # Save result info in DataFrame\n","  inference_df = pd.DataFrame(test_inference_results)\n","  # Save result info as .csv\n","  inference_df.to_csv(target_path_1, index=False, header=header_1)\n","  # Save .csv to weights & biases\n","  inference_df.to_csv(\"test_inference_results.csv\", index=False, header=header_1)\n","  wandb.save('test_inference_results.csv')\n","  \n","  # Track classification quality to weights & biases\n","  targets = [i[1] for i in test_inference_results]\n","  outputs = [i[2] for i in test_inference_results]\n","  accuracy = accuracy_score(targets, outputs)\n","  # Calculate test classification quality parameters\n","  macro_precision, macro_recall, macro_fscore,_ = precision_recall_fscore_support(targets, outputs, average='macro')\n","  wandb.run.summary[\"Test Accuracy\"] = accuracy\n","  wandb.run.summary[\"Test Macro F-Score\"] = macro_fscore\n","  wandb.run.summary[\"Test Macro Precision\"] = macro_precision\n","  wandb.run.summary[\"Test Macro Recall\"] = macro_recall\n","  print(\"Test Accuracy: \" + str(accuracy))\n","\n","  # Calculate confidence chart\n","  conf_graph_data = []\n","  header_2 = [\"Conficence\",\"Accuracy\",\"Macro Precision\",\"Macro Recall\",\"Macro F-Score\",\"Percentage predicted\"]\n","  # Iterate confidence threshold steps\n","  for c in range(1,100,2):\n","    subset = [[targ,pred] for _,targ,pred,conf in test_inference_results if conf >= c/100]\n","    if subset:\n","      targets, outputs = zip(*subset)\n","      accuracy = accuracy_score(targets, outputs)\n","      macro_precision, macro_recall, macro_fscore,_ = precision_recall_fscore_support(targets, outputs, average='micro')\n","      perc_predicted = len(subset)/len(test_inference_results)\n","      conf_graph_data.append([c/100,round(accuracy,2),round(macro_precision,2),round(macro_recall,2),round(macro_fscore,2),round(perc_predicted,2)])\n","  # save confidence chart\n","  conf_graph_df = pd.DataFrame(conf_graph_data)\n","  conf_graph_df.to_csv(target_path_2, index=False, header=header_2)\n","  conf_graph_df.to_csv(\"test_inference_results_confidences.csv\", index=False, header=header_2)\n","  wandb.save('test_inference_results_confidences.csv')\n","\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JcBZyp_1IKKB"},"source":["\n","# MAIN\n","This cell runs the functions that were defined above"]},{"cell_type":"code","metadata":{"id":"2tDiil3nIIt7"},"source":["# Create image folders of the dataset\n","n_classes,size_table = create_image_folders(csv_path, zip_path, IRI_BINNING, datadir, dirs, splits, DATA_BLOCKS, OVERSAMPLING, OVERSAMPLING_VAL_TEST)\n","\n","# If foreign test data is used, replace the test image folders\n","if test_location is not \"same\":\n","  print(\"Creating special Test-Set for \" + test_location)\n","  test_location_splits = {\"train_part\" : 0.6,  \"val_part\" : 0.2,  \"test_part\" : 0.2}\n","  create_image_folders(test_csv_path, test_zip_path, IRI_BINNING, test_datadir, test_dirs, test_location_splits, DATA_BLOCKS, OVERSAMPLING, OVERSAMPLING_VAL_TEST)\n","  #overwrite original test data with selected test data\n","  rmtree(dirs[\"test\"])\n","  copytree(test_dirs[\"test\"],dirs[\"test\"])\n","\n","# Create datasets and dataloaders\n","data, dataloaders = create_datasets(dirs, INPUT_SIZE, BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PmBlu-SRyVHX"},"source":["#### Start training"]},{"cell_type":"code","metadata":{"id":"kammOHlE2oQ_"},"source":["training_combinations = [\n","                         #[0.0001,0.4,0],\n","                         [0.0001,0.4,0.0001],#######\n","                         #[0.0001,0.5,0],\n","                         #[0.0001,0.5,0.0001],\n","                         #[0.001,0.4,0],\n","                         #[0.001,0.4,0.0001],\n","                         #[0.001,0.5,0],\n","                         #[0.001,0.5,0.0001],\n","                         #[0.01,0.4,0],\n","                         #[0.01,0.4,0.0001],\n","                         #[0.01,0.5,0],\n","                         #[0.01,0.5,0.0001]\n","                         ]\n","\n","# Iterate through training parameters and run training procedure\n","run_count = 0\n","for LR,DROPOUT,WEIGHT_INCREASE in training_combinations:\n","  for repetition in range(number_of_repetitions):\n","    run_count += 1\n","    print(\"+++++  Starting run {}. (LR:{}, Dropout:{}, Sample Weights:{})\".format(run_count,LR,DROPOUT,WEIGHT_INCREASE))\n","    \n","    # Load pretrained model\n","    model = get_pretrained_model(MODEL_NAME, multi_gpu, DROPOUT, FROZEN)\n","    \n","    # Initialize Weights & Biases run\n","    wandb.init(project=wandb_project, reinit=True, entity=\"rdd\")\n","    try:\n","      wandb.watch(model)\n","    except:\n","      pass\n","\n","    training_parameters = (\n","        model,\n","        LR,\n","        dataloaders['train'],\n","        dataloaders['val'],\n","        save_file_name,\n","        MAX_EPOCHS_STOP,\n","        'NLLLoss',\n","        WEIGHT_INCREASE,\n","        N_EPOCHS)\n","\n","    # Document parameter configuration to Weights & Biases\n","    wandb.config.update({\n","        \"Model name\": MODEL_NAME,\n","        \"Training batch size\": BATCH_SIZE,\n","        \"Learning rate\": LR,\n","        \"Max number of epochs\": N_EPOCHS,\n","        \"Max epochs stop\": MAX_EPOCHS_STOP,\n","        \"Input image size\": INPUT_SIZE,\n","        \"Frozen pretrained weights\": FROZEN,\n","        \"Dropout percentage\": DROPOUT,\n","        \"Sample weight increase\": WEIGHT_INCREASE,\n","        \"IRI Binning\": IRI_BINNING,\n","        \"Blockwise data sampling\": DATA_BLOCKS,\n","        \"Oversampling\": OVERSAMPLING,\n","        \"Oversampling Val & Test\":OVERSAMPLING_VAL_TEST,\n","        \"Training splits\": splits,\n","        \"IRI csv file\": csv_path,\n","        \"Image dataset\": zip_path,\n","        \"Train location\": ride_location,\n","        \"Test location\": test_location,\n","        \"Run title\": run_title\n","        })\n","    \n","    # Start training\n","    model, history, sample_weights = train(*training_parameters)\n","\n","    # Get test results\n","    test_inference(model,dataloaders)\n","    \n","    try:\n","      # Track model info on Weights & Biases\n","      wandb.watch(model)\n","    except:\n","      pass"],"execution_count":null,"outputs":[]}]}